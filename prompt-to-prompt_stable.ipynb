{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "cyiII5YPPHoN"
      },
      "source": [
        "## Copyright 2022 Google LLC. Double-click for license information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yj0tKQWnPHoP"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.12.1"
      ],
      "metadata": {
        "id": "bb7O7TTMb9wn",
        "outputId": "6757e6e5-b973-41fc-a2a2-730218fb8491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub==0.12.1 in /usr/local/lib/python3.11/dist-packages (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (4.14.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.12.1) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.12.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.12.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.12.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.12.1) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tokenizers==0.13.2 diffusers==0.14.0 transformers==4.26.1 accelerate==0.15.0 ftfy==6.1.1\n"
      ],
      "metadata": {
        "id": "dt-0YxMcPbGr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"jax[cpu]==0.4.13\" -q\n"
      ],
      "metadata": {
        "id": "LZdc-NFwcYTx",
        "outputId": "a740d24d-b7e7-4ae4-8551-bf40ef37e7d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.89 requires jax>=0.4.27, but you have jax 0.4.13 which is incompatible.\n",
            "chex 0.1.89 requires jaxlib>=0.4.27, but you have jaxlib 0.4.13 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.13 which is incompatible.\n",
            "optax 0.2.5 requires jax>=0.4.27, but you have jax 0.4.13 which is incompatible.\n",
            "optax 0.2.5 requires jaxlib>=0.4.27, but you have jaxlib 0.4.13 which is incompatible.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.13 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/prompt-to-prompt')\n"
      ],
      "metadata": {
        "id": "sT6_UhP2Pdps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "VDI5esdZPHoQ"
      },
      "source": [
        "## Prompt-to-Prompt with Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ugE3O1WBPHoQ",
        "outputId": "049f236e-1d9a-4099-93e4-7ce1eca0bafc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 0>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtyping\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m Optional, Union, Tuple, List, Callable, Dict                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtorch\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96mdiffusers\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m StableDiffusionPipeline\u001b[0m                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtorch\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mnn\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mfunctional\u001b[0m\u001b[90m \u001b[0m\u001b[94mas\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mnnf\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mnumpy\u001b[0m\u001b[90m \u001b[0m\u001b[94mas\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mnp\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mabc\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/diffusers/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m35\u001b[0m in \u001b[92m<module>\u001b[0m                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[94mexcept\u001b[0m OptionalDependencyNotAvailable:                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 33 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mutils\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mdummy_pt_objects\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m *  \u001b[2m# noqa F403\u001b[0m                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[94melse\u001b[0m:                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 35 \u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmodels\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m (                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0mAutoencoderKL,                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 37 \u001b[0m\u001b[2m│   │   \u001b[0mControlNetModel,                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 38 \u001b[0m\u001b[2m│   │   \u001b[0mModelMixin,                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/diffusers/models/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m31\u001b[0m in \u001b[92m<module>\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mvq_model\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m VQModel                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[94mif\u001b[0m is_flax_available():                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m31 \u001b[2m│   \u001b[0m\u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96munet_2d_condition_flax\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m FlaxUNet2DConditionModel\u001b[0m                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mvae_flax\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m FlaxAutoencoderKL                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_condition_flax.py\u001b[0m:\u001b[94m25\u001b[0m in         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92m<module>\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 22 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mconfiguration_utils\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m ConfigMixin, flax_register_to_config                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 23 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mutils\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m BaseOutput                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96membeddings_flax\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m FlaxTimestepEmbedding, FlaxTimesteps                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 25 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96m.\u001b[0m\u001b[1;4;96mmodeling_flax_utils\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m FlaxModelMixin\u001b[0m                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96munet_2d_blocks_flax\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m (                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 27 \u001b[0m\u001b[2m│   \u001b[0mFlaxCrossAttnDownBlock2D,                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m│   \u001b[0mFlaxCrossAttnUpBlock2D,                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mmodeling_flax_utils.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92m<module>\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0mlogger = logging.get_logger(\u001b[91m__name__\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 45 \u001b[94mclass\u001b[0m\u001b[90m \u001b[0m\u001b[4;92mFlaxModelMixin\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mBase class for all flax models.\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 48 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/diffusers/models/\u001b[0m\u001b[1;33mmodeling_flax_utils.py\u001b[0m:\u001b[94m192\u001b[0m in           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mFlaxModelMixin\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._cast_floating_to(params, jnp.float16, mask)                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m192 \u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92minit_weights\u001b[0m(\u001b[96mself\u001b[0m, rng: \u001b[1;4mjax.random.KeyArray\u001b[0m) -> Dict:                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33minit_weights method has to be implemented for \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m\u001b[33m}\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mAttributeError: \u001b[0mmodule \u001b[32m'jax.random'\u001b[0m has no attribute \u001b[32m'KeyArray'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 0&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">typing</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> Optional, Union, Tuple, List, Callable, Dict                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torch</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">from</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">diffusers</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">import</span><span style=\"font-weight: bold; text-decoration: underline\"> StableDiffusionPipeline</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torch.nn.functional</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">nnf</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">numpy</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">np</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">abc</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.11/dist-packages/diffusers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> OptionalDependencyNotAvailable:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.utils.dummy_pt_objects</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> *  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># noqa F403</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.models</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> (                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>AutoencoderKL,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ControlNetModel,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ModelMixin,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.11/dist-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">31</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.vq_model</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> VQModel                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_flax_available():                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>31 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">from</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">.unet_2d_condition_flax</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">import</span><span style=\"font-weight: bold; text-decoration: underline\"> FlaxUNet2DConditionModel</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.vae_flax</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> FlaxAutoencoderKL                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.11/dist-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_2d_condition_flax.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">25</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 22 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">..configuration_utils</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> ConfigMixin, flax_register_to_config                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">..utils</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> BaseOutput                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.embeddings_flax</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> FlaxTimestepEmbedding, FlaxTimesteps                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 25 <span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">from</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">.modeling_flax_utils</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">import</span><span style=\"font-weight: bold; text-decoration: underline\"> FlaxModelMixin</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.unet_2d_blocks_flax</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> (                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>FlaxCrossAttnDownBlock2D,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>FlaxCrossAttnUpBlock2D,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.11/dist-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_flax_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">45</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 </span>logger = logging.get_logger(<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 45 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">FlaxModelMixin</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">r\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Base class for all flax models.</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 48 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.11/dist-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_flax_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">192</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">FlaxModelMixin</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._cast_floating_to(params, jnp.float16, mask)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>192 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">init_weights</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, rng: <span style=\"font-weight: bold; text-decoration: underline\">jax.random.KeyArray</span>) -&gt; Dict:                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"init_weights method has to be implemented for {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span><span style=\"color: #808000; text-decoration-color: #808000\">}</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span>module <span style=\"color: #008000; text-decoration-color: #008000\">'jax.random'</span> has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'KeyArray'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import Optional, Union, Tuple, List, Callable, Dict\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch.nn.functional as nnf\n",
        "import numpy as np\n",
        "import abc\n",
        "import ptp_utils\n",
        "import seq_aligner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Qw-c9_65PHoQ"
      },
      "source": [
        "For loading the Stable Diffusion using Diffusers, follow the instuctions https://huggingface.co/blog/stable_diffusion and update ```MY_TOKEN``` with your token.\n",
        "Set ```LOW_RESOURCE``` to ```True``` for running on 12GB GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [],
        "id": "UFS4vOvQPHoR"
      },
      "outputs": [],
      "source": [
        "MY_TOKEN = '<replace with your token>'\n",
        "LOW_RESOURCE = False\n",
        "NUM_DIFFUSION_STEPS = 50\n",
        "GUIDANCE_SCALE = 7.5\n",
        "MAX_NUM_WORDS = 77\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "ldm_stable = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=MY_TOKEN).to(device)\n",
        "tokenizer = ldm_stable.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ptp_utils\n",
        "import torch\n",
        "\n",
        "def patched_text2image_ldm_stable(\n",
        "    model, prompt, controller, num_inference_steps, guidance_scale, generator, latent, low_resource\n",
        "):\n",
        "    # Tokenize prompt\n",
        "    context = model.tokenizer(prompt, padding=\"max_length\", max_length=77, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "    # Initialize latent noise if none given\n",
        "    if latent is None:\n",
        "        latents = torch.randn(\n",
        "            (1, model.unet.in_channels, model.unet.sample_size, model.unet.sample_size),\n",
        "            generator=generator,\n",
        "            device=model.device,\n",
        "        )\n",
        "    else:\n",
        "        latents = latent\n",
        "\n",
        "    # Set up scheduler (modern API)\n",
        "    model.scheduler.set_timesteps(num_inference_steps)\n",
        "\n",
        "    # Run diffusion\n",
        "    for t in model.scheduler.timesteps:\n",
        "        latents = ptp_utils.diffusion_step(model, controller, latents, context, t, guidance_scale, low_resource)\n",
        "\n",
        "    # Convert to images\n",
        "    images = ptp_utils.latents_to_pil(latents, model)\n",
        "    return images, latents\n",
        "\n",
        "ptp_utils.text2image_ldm_stable = patched_text2image_ldm_stable\n",
        "print(\"✅ Patched ptp_utils.text2image_ldm_stable with proper latent init + no offset\")\n"
      ],
      "metadata": {
        "id": "rcvbazkmXqyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "L-_y24uxPHoR"
      },
      "source": [
        "## Prompt-to-Prompt Attnetion Controllers\n",
        "Our main logic is implemented in the `forward` call in an `AttentionControl` object.\n",
        "The forward is called in each attention layer of the diffusion model and it can modify the input attnetion weights `attn`.\n",
        "\n",
        "`is_cross`, `place_in_unet in (\"down\", \"mid\", \"up\")`, `AttentionControl.cur_step` help us track the exact attention layer and timestamp during the diffusion iference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnEOkRK3PHoR"
      },
      "outputs": [],
      "source": [
        "class LocalBlend:\n",
        "\n",
        "    def __call__(self, x_t, attention_store):\n",
        "        k = 1\n",
        "        maps = attention_store[\"down_cross\"][2:4] + attention_store[\"up_cross\"][:3]\n",
        "        maps = [item.reshape(self.alpha_layers.shape[0], -1, 1, 16, 16, MAX_NUM_WORDS) for item in maps]\n",
        "        maps = torch.cat(maps, dim=1)\n",
        "        maps = (maps * self.alpha_layers).sum(-1).mean(1)\n",
        "        mask = nnf.max_pool2d(maps, (k * 2 + 1, k * 2 +1), (1, 1), padding=(k, k))\n",
        "        mask = nnf.interpolate(mask, size=(x_t.shape[2:]))\n",
        "        mask = mask / mask.max(2, keepdims=True)[0].max(3, keepdims=True)[0]\n",
        "        mask = mask.gt(self.threshold)\n",
        "        mask = (mask[:1] + mask[1:]).float()\n",
        "        x_t = x_t[:1] + mask * (x_t - x_t[:1])\n",
        "        return x_t\n",
        "\n",
        "    def __init__(self, prompts: List[str], words: [List[List[str]]], threshold=.3):\n",
        "        alpha_layers = torch.zeros(len(prompts),  1, 1, 1, 1, MAX_NUM_WORDS)\n",
        "        for i, (prompt, words_) in enumerate(zip(prompts, words)):\n",
        "            if type(words_) is str:\n",
        "                words_ = [words_]\n",
        "            for word in words_:\n",
        "                ind = ptp_utils.get_word_inds(prompt, word, tokenizer)\n",
        "                alpha_layers[i, :, :, :, :, ind] = 1\n",
        "        self.alpha_layers = alpha_layers.to(device)\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "class AttentionControl(abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        return x_t\n",
        "\n",
        "    def between_steps(self):\n",
        "        return\n",
        "\n",
        "    @property\n",
        "    def num_uncond_att_layers(self):\n",
        "        return self.num_att_layers if LOW_RESOURCE else 0\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __call__(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        if self.cur_att_layer >= self.num_uncond_att_layers:\n",
        "            if LOW_RESOURCE:\n",
        "                attn = self.forward(attn, is_cross, place_in_unet)\n",
        "            else:\n",
        "                h = attn.shape[0]\n",
        "                attn[h // 2:] = self.forward(attn[h // 2:], is_cross, place_in_unet)\n",
        "        self.cur_att_layer += 1\n",
        "        if self.cur_att_layer == self.num_att_layers + self.num_uncond_att_layers:\n",
        "            self.cur_att_layer = 0\n",
        "            self.cur_step += 1\n",
        "            self.between_steps()\n",
        "        return attn\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_step = 0\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cur_step = 0\n",
        "        self.num_att_layers = -1\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "class EmptyControl(AttentionControl):\n",
        "\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        return attn\n",
        "\n",
        "\n",
        "class AttentionStore(AttentionControl):\n",
        "\n",
        "    @staticmethod\n",
        "    def get_empty_store():\n",
        "        return {\"down_cross\": [], \"mid_cross\": [], \"up_cross\": [],\n",
        "                \"down_self\": [],  \"mid_self\": [],  \"up_self\": []}\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        key = f\"{place_in_unet}_{'cross' if is_cross else 'self'}\"\n",
        "        if attn.shape[1] <= 32 ** 2:  # avoid memory overhead\n",
        "            self.step_store[key].append(attn)\n",
        "        return attn\n",
        "\n",
        "    def between_steps(self):\n",
        "        if len(self.attention_store) == 0:\n",
        "            self.attention_store = self.step_store\n",
        "        else:\n",
        "            for key in self.attention_store:\n",
        "                for i in range(len(self.attention_store[key])):\n",
        "                    self.attention_store[key][i] += self.step_store[key][i]\n",
        "        self.step_store = self.get_empty_store()\n",
        "\n",
        "    def get_average_attention(self):\n",
        "        average_attention = {key: [item / self.cur_step for item in self.attention_store[key]] for key in self.attention_store}\n",
        "        return average_attention\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        super(AttentionStore, self).reset()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AttentionStore, self).__init__()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "\n",
        "class AttentionControlEdit(AttentionStore, abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        if self.local_blend is not None:\n",
        "            x_t = self.local_blend(x_t, self.attention_store)\n",
        "        return x_t\n",
        "\n",
        "    def replace_self_attention(self, attn_base, att_replace):\n",
        "        if att_replace.shape[2] <= 16 ** 2:\n",
        "            return attn_base.unsqueeze(0).expand(att_replace.shape[0], *attn_base.shape)\n",
        "        else:\n",
        "            return att_replace\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        super(AttentionControlEdit, self).forward(attn, is_cross, place_in_unet)\n",
        "        if is_cross or (self.num_self_replace[0] <= self.cur_step < self.num_self_replace[1]):\n",
        "            h = attn.shape[0] // (self.batch_size)\n",
        "            attn = attn.reshape(self.batch_size, h, *attn.shape[1:])\n",
        "            attn_base, attn_repalce = attn[0], attn[1:]\n",
        "            if is_cross:\n",
        "                alpha_words = self.cross_replace_alpha[self.cur_step]\n",
        "                attn_repalce_new = self.replace_cross_attention(attn_base, attn_repalce) * alpha_words + (1 - alpha_words) * attn_repalce\n",
        "                attn[1:] = attn_repalce_new\n",
        "            else:\n",
        "                attn[1:] = self.replace_self_attention(attn_base, attn_repalce)\n",
        "            attn = attn.reshape(self.batch_size * h, *attn.shape[2:])\n",
        "        return attn\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int,\n",
        "                 cross_replace_steps: Union[float, Tuple[float, float], Dict[str, Tuple[float, float]]],\n",
        "                 self_replace_steps: Union[float, Tuple[float, float]],\n",
        "                 local_blend: Optional[LocalBlend]):\n",
        "        super(AttentionControlEdit, self).__init__()\n",
        "        self.batch_size = len(prompts)\n",
        "        self.cross_replace_alpha = ptp_utils.get_time_words_attention_alpha(prompts, num_steps, cross_replace_steps, tokenizer).to(device)\n",
        "        if type(self_replace_steps) is float:\n",
        "            self_replace_steps = 0, self_replace_steps\n",
        "        self.num_self_replace = int(num_steps * self_replace_steps[0]), int(num_steps * self_replace_steps[1])\n",
        "        self.local_blend = local_blend\n",
        "\n",
        "class AttentionReplace(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        return torch.einsum('hpw,bwn->bhpn', attn_base, self.mapper)\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionReplace, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper = seq_aligner.get_replacement_mapper(prompts, tokenizer).to(device)\n",
        "\n",
        "\n",
        "class AttentionRefine(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        attn_base_replace = attn_base[:, :, self.mapper].permute(2, 0, 1, 3)\n",
        "        attn_replace = attn_base_replace * self.alphas + att_replace * (1 - self.alphas)\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionRefine, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper, alphas = seq_aligner.get_refinement_mapper(prompts, tokenizer)\n",
        "        self.mapper, alphas = self.mapper.to(device), alphas.to(device)\n",
        "        self.alphas = alphas.reshape(alphas.shape[0], 1, 1, alphas.shape[1])\n",
        "\n",
        "\n",
        "class AttentionReweight(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        if self.prev_controller is not None:\n",
        "            attn_base = self.prev_controller.replace_cross_attention(attn_base, att_replace)\n",
        "        attn_replace = attn_base[None, :, :, :] * self.equalizer[:, None, None, :]\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float, equalizer,\n",
        "                local_blend: Optional[LocalBlend] = None, controller: Optional[AttentionControlEdit] = None):\n",
        "        super(AttentionReweight, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.equalizer = equalizer.to(device)\n",
        "        self.prev_controller = controller\n",
        "\n",
        "\n",
        "def get_equalizer(text: str, word_select: Union[int, Tuple[int, ...]], values: Union[List[float],\n",
        "                  Tuple[float, ...]]):\n",
        "    if type(word_select) is int or type(word_select) is str:\n",
        "        word_select = (word_select,)\n",
        "    equalizer = torch.ones(len(values), 77)\n",
        "    values = torch.tensor(values, dtype=torch.float32)\n",
        "    for word in word_select:\n",
        "        inds = ptp_utils.get_word_inds(text, word, tokenizer)\n",
        "        equalizer[:, inds] = values\n",
        "    return equalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_MtW3niTPHoS"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def aggregate_attention(attention_store: AttentionStore, res: int, from_where: List[str], is_cross: bool, select: int):\n",
        "    out = []\n",
        "    attention_maps = attention_store.get_average_attention()\n",
        "    num_pixels = res ** 2\n",
        "    for location in from_where:\n",
        "        for item in attention_maps[f\"{location}_{'cross' if is_cross else 'self'}\"]:\n",
        "            if item.shape[1] == num_pixels:\n",
        "                cross_maps = item.reshape(len(prompts), -1, res, res, item.shape[-1])[select]\n",
        "                out.append(cross_maps)\n",
        "    out = torch.cat(out, dim=0)\n",
        "    out = out.sum(0) / out.shape[0]\n",
        "    return out.cpu()\n",
        "\n",
        "\n",
        "def show_cross_attention(attention_store: AttentionStore, res: int, from_where: List[str], select: int = 0):\n",
        "    tokens = tokenizer.encode(prompts[select])\n",
        "    decoder = tokenizer.decode\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, True, select)\n",
        "    images = []\n",
        "    for i in range(len(tokens)):\n",
        "        image = attention_maps[:, :, i]\n",
        "        image = 255 * image / image.max()\n",
        "        image = image.unsqueeze(-1).expand(*image.shape, 3)\n",
        "        image = image.numpy().astype(np.uint8)\n",
        "        image = np.array(Image.fromarray(image).resize((256, 256)))\n",
        "        image = ptp_utils.text_under_image(image, decoder(int(tokens[i])))\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.stack(images, axis=0))\n",
        "\n",
        "\n",
        "def show_self_attention_comp(attention_store: AttentionStore, res: int, from_where: List[str],\n",
        "                        max_com=10, select: int = 0):\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, False, select).numpy().reshape((res ** 2, res ** 2))\n",
        "    u, s, vh = np.linalg.svd(attention_maps - np.mean(attention_maps, axis=1, keepdims=True))\n",
        "    images = []\n",
        "    for i in range(max_com):\n",
        "        image = vh[i].reshape(res, res)\n",
        "        image = image - image.min()\n",
        "        image = 255 * image / image.max()\n",
        "        image = np.repeat(np.expand_dims(image, axis=2), 3, axis=2).astype(np.uint8)\n",
        "        image = Image.fromarray(image).resize((256, 256))\n",
        "        image = np.array(image)\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.concatenate(images, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MwbjFGySPHoS"
      },
      "outputs": [],
      "source": [
        "def run_and_display(prompts, controller, latent=None, run_baseline=False, generator=None):\n",
        "    if run_baseline:\n",
        "        print(\"w.o. prompt-to-prompt\")\n",
        "        images, latent = run_and_display(prompts, EmptyControl(), latent=latent, run_baseline=False, generator=generator)\n",
        "        print(\"with prompt-to-prompt\")\n",
        "    images, x_t = ptp_utils.text2image_ldm_stable(ldm_stable, prompts, controller, latent=latent, num_inference_steps=NUM_DIFFUSION_STEPS, guidance_scale=GUIDANCE_SCALE, generator=generator, low_resource=LOW_RESOURCE)\n",
        "    ptp_utils.view_images(images)\n",
        "    return images, x_t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/model.scheduler.set_timesteps(num_inference_steps, \\*\\*extra_set_kwargs)/model.scheduler.set_timesteps(num_inference_steps)/' ptp_utils.py\n",
        "!sed -i 's/extra_set_kwargs = {\"offset\": 1}/# removed offset argument for new diffusers API/' ptp_utils.py\n"
      ],
      "metadata": {
        "id": "sDdD_y2IP7GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "o9o2_iMhPHoT"
      },
      "source": [
        "## Cross-Attention Visualization\n",
        "First let's generate an image and visualize the cross-attention maps for each word in the prompt.\n",
        "Notice, we normalize each map to 0-1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qosMw07wPHoT"
      },
      "outputs": [],
      "source": [
        "g_cuda = torch.Generator(device=\"cuda\").manual_seed(8888)\n",
        "prompts = [\"A painting of a squirrel eating a burger\"]\n",
        "controller = AttentionStore()\n",
        "image, x_t = run_and_display(prompts, controller, latent=None, run_baseline=False, generator=g_cuda)\n",
        "show_cross_attention(controller, res=16, from_where=(\"up\", \"down\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "mZvcC3m1PHoT"
      },
      "source": [
        "## Replacement edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "O1757WPtPHoT"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A painting of a lion eating a burger\"]\n",
        "\n",
        "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8, self_replace_steps=0.4)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xBfv4Y3iPHoT"
      },
      "source": [
        "### Modify Cross-Attention injection #steps for specific words\n",
        "Next, we can reduce the restriction on our lion by reducing the number of cross-attention injection with respect to the word \"lion\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KEU60sfIPHoT"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A painting of a lion eating a burger\"]\n",
        "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps={\"default_\": 1., \"lion\": .4},\n",
        "                              self_replace_steps=0.4)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vv6FwfxePHoT"
      },
      "source": [
        "### Local Edit\n",
        "Lastly, if we want to preseve the original burger, we can apply a local edit with respect to the squirrel and the lion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Wti-FQ1QPHoT"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A painting of a lion eating a burger\"]\n",
        "lb = LocalBlend(prompts, (\"squirrel\", \"lion\"))\n",
        "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS,\n",
        "                              cross_replace_steps={\"default_\": 1., \"lion\": .4},\n",
        "                              self_replace_steps=0.4, local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6A-QbQF0PHoT"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A painting of a squirrel eating a lasagne\"]\n",
        "lb = LocalBlend(prompts, (\"burger\", \"lasagne\"))\n",
        "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS,\n",
        "                              cross_replace_steps={\"default_\": 1., \"lasagne\": .2},\n",
        "                              self_replace_steps=0.4,\n",
        "                              local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "tags": [],
        "id": "rzHjcqbMPHoT"
      },
      "source": [
        "## Refinement edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ybZDyERcPHoT"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A neoclassical painting of a squirrel eating a burger\"]\n",
        "\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS,\n",
        "                             cross_replace_steps=.5,\n",
        "                             self_replace_steps=.2)\n",
        "_ = run_and_display(prompts, controller, latent=x_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IIiTs1eHPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"a photo of a house on a mountain\",\n",
        "           \"a photo of a house on a mountain at fall\"]\n",
        "\n",
        "\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4)\n",
        "_ = run_and_display(prompts, controller, latent=x_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "u-l50lttPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"a photo of a house on a mountain\",\n",
        "           \"a photo of a house on a mountain at winter\"]\n",
        "\n",
        "\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4)\n",
        "_ = run_and_display(prompts, controller, latent=x_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBy8b13RPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"soup\",\n",
        "           \"pea soup\"]\n",
        "\n",
        "lb = LocalBlend(prompts, (\"soup\", \"soup\"))\n",
        "\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4,\n",
        "                             local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US5CkDDyPHoU"
      },
      "source": [
        "## Attention Re-Weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX0-w3r0PHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"a smiling bunny doll\"] * 2\n",
        "\n",
        "### pay 3 times more attention to the word \"smiling\"\n",
        "equalizer = get_equalizer(prompts[1], (\"smiling\",), (5,))\n",
        "controller = AttentionReweight(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                               self_replace_steps=.4,\n",
        "                               equalizer=equalizer)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM79fn1vPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"pink bear riding a bicycle\"] * 2\n",
        "\n",
        "### we don't wont pink bikes, only pink bear.\n",
        "### we reduce the amount of pink but apply it locally on the bikes (attention re-weight + local mask )\n",
        "\n",
        "### pay less attention to the word \"pink\"\n",
        "equalizer = get_equalizer(prompts[1], (\"pink\",), (-1,))\n",
        "\n",
        "### apply the edit on the bikes\n",
        "lb = LocalBlend(prompts, (\"bicycle\", \"bicycle\"))\n",
        "controller = AttentionReweight(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                               self_replace_steps=.4,\n",
        "                               equalizer=equalizer,\n",
        "                               local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_sTqufnPHoU"
      },
      "source": [
        "### Where are my croutons?\n",
        "It might be useful to use Attention Re-Weighting with a previous edit method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uzfLFuQPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"soup\",\n",
        "           \"pea soup with croutons\"]\n",
        "lb = LocalBlend(prompts, (\"soup\", \"soup\"))\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4, local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6pAkbyVPHoU"
      },
      "source": [
        "Now, with more attetnion to `\"croutons\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah1aVeO0PHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"soup\",\n",
        "           \"pea soup with croutons\"]\n",
        "\n",
        "\n",
        "lb = LocalBlend(prompts, (\"soup\", \"soup\"))\n",
        "controller_a = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                               self_replace_steps=.4, local_blend=lb)\n",
        "\n",
        "### pay 3 times more attention to the word \"croutons\"\n",
        "equalizer = get_equalizer(prompts[1], (\"croutons\",), (3,))\n",
        "controller = AttentionReweight(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                               self_replace_steps=.4, equalizer=equalizer, local_blend=lb,\n",
        "                               controller=controller_a)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1YVUd1sPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"potatos\",\n",
        "           \"fried potatos\"]\n",
        "lb = LocalBlend(prompts, (\"potatos\", \"potatos\"))\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4, local_blend=lb)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EtCKm9LPHoU"
      },
      "outputs": [],
      "source": [
        "prompts = [\"potatos\",\n",
        "           \"fried potatos\"]\n",
        "lb = LocalBlend(prompts, (\"potatos\", \"potatos\"))\n",
        "controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                             self_replace_steps=.4, local_blend=lb)\n",
        "\n",
        "### pay 10 times more attention to the word \"fried\"\n",
        "equalizer = get_equalizer(prompts[1], (\"fried\",), (10,))\n",
        "controller = AttentionReweight(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8,\n",
        "                               self_replace_steps=.4, equalizer=equalizer, local_blend=lb,\n",
        "                               controller=controller_a)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaEoLvaFPHoU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-11.m94",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}